# Hyperparameter Tuning Parameters
hyperparameter_tuning:
  n_trials: 50
  optimization_metric: "recall"
  cv_folds: 5
  random_state: 42
  direction: "maximize"
  pruning: true
  timeout: null  # No timeout by default

  # Search spaces for each model type
  logistic_regression:
    C:
      type: "float"
      low: 0.001
      high: 100.0
      log: true
    max_iter:
      type: "int"
      low: 100
      high: 2000

  random_forest:
    n_estimators:
      type: "int"
      low: 50
      high: 300
    max_depth:
      type: "int"
      low: 3
      high: 20
    min_samples_split:
      type: "int"
      low: 2
      high: 20
    min_samples_leaf:
      type: "int"
      low: 1
      high: 10

  gradient_boosting:
    n_estimators:
      type: "int"
      low: 50
      high: 300
    learning_rate:
      type: "float"
      low: 0.01
      high: 0.3
      log: true
    max_depth:
      type: "int"
      low: 2
      high: 10
    min_samples_split:
      type: "int"
      low: 2
      high: 20
    min_samples_leaf:
      type: "int"
      low: 1
      high: 10



# Model Training Parameters
model_training:
  # Data split parameters
  target_column: "Churn"
  test_size: 0.2
  random_state: 42

  # Model selection metric (accuracy, precision, recall, f1_score, roc_auc)
  selection_metric: "recall"

  # Logistic Regression parameters
  logistic_regression:
    C: 1.0
    max_iter: 1000
    class_weight: "balanced"

  # Random Forest parameters
  random_forest:
    n_estimators: 100
    max_depth: 10
    min_samples_split: 2
    min_samples_leaf: 1
    class_weight: "balanced"

  # Gradient Boosting parameters
  gradient_boosting:
    n_estimators: 100
    learning_rate: 0.1
    max_depth: 3
    min_samples_split: 2
    min_samples_leaf: 1

